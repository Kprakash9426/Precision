{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     S.No         Crop  Dist_id       District       Year  Season  \\\n",
      "0       1    groundnut        1       ADILABAD  2016-2017  kharif   \n",
      "1       2    groundnut       11  KOMARAM BHEEM  2016-2017  kharif   \n",
      "2       4    groundnut       13     MANCHERIAL  2016-2017  kharif   \n",
      "3       5    groundnut       21         NIRMAL  2016-2017  kharif   \n",
      "4       6    groundnut       22      NIZAMABAD  2016-2017  kharif   \n",
      "..    ...          ...      ...            ...        ...     ...   \n",
      "553   555  bengal gram       30     WANAPARTHY  2018-2019    rabi   \n",
      "554   556  bengal gram       18   NAGARKURNOOL  2018-2019    rabi   \n",
      "555   557  bengal gram       19       NALGONDA  2018-2019    rabi   \n",
      "556   558  bengal gram       28       SURYAPET  2018-2019    rabi   \n",
      "557   559  bengal gram       10        KHAMMAM  2018-2019    rabi   \n",
      "\n",
      "     Season_yield  Total  \n",
      "0               0   2068  \n",
      "1               0   2068  \n",
      "2            1930   2066  \n",
      "3               0   2068  \n",
      "4            1930   2044  \n",
      "..            ...    ...  \n",
      "553          2140   2140  \n",
      "554          1569   1569  \n",
      "555          1569   1569  \n",
      "556          1569   1569  \n",
      "557          1569   1569  \n",
      "\n",
      "[558 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_excel(r\"E:\\udmey\\Precision Farming to Impove the yield\\1_yield_data.xlsx\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Dist_id</th>\n",
       "      <th>District</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Season_yield</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>1</td>\n",
       "      <td>ADILABAD</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>0</td>\n",
       "      <td>2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>11</td>\n",
       "      <td>KOMARAM BHEEM</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>0</td>\n",
       "      <td>2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>13</td>\n",
       "      <td>MANCHERIAL</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>1930</td>\n",
       "      <td>2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>21</td>\n",
       "      <td>NIRMAL</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>0</td>\n",
       "      <td>2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>22</td>\n",
       "      <td>NIZAMABAD</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>1930</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>4</td>\n",
       "      <td>JAGTIAL</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>0</td>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>23</td>\n",
       "      <td>PEDDAPALLI</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>0</td>\n",
       "      <td>2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>6</td>\n",
       "      <td>JAYASHANKAR</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>3723</td>\n",
       "      <td>2151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>2</td>\n",
       "      <td>BHADRADRI</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>1930</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>16</td>\n",
       "      <td>MAHABUBABAD</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>3723</td>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>31</td>\n",
       "      <td>WARANGAL RURAL</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>3723</td>\n",
       "      <td>3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>32</td>\n",
       "      <td>WARANGAL URBAN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>3723</td>\n",
       "      <td>2416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>9</td>\n",
       "      <td>KARIMNAGAR</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>1930</td>\n",
       "      <td>2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>24</td>\n",
       "      <td>RAJANNA</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>0</td>\n",
       "      <td>2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>8</td>\n",
       "      <td>KAMAREDDY</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>0</td>\n",
       "      <td>2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>26</td>\n",
       "      <td>SANGAREDDY</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>1930</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>14</td>\n",
       "      <td>MEDAK</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>1930</td>\n",
       "      <td>2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>27</td>\n",
       "      <td>SIDDIPET</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>1930</td>\n",
       "      <td>2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>5</td>\n",
       "      <td>JANGAON</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>3723</td>\n",
       "      <td>1516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>33</td>\n",
       "      <td>YADADRI</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>kharif</td>\n",
       "      <td>1671</td>\n",
       "      <td>1736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    S.No       Crop  Dist_id        District       Year  Season  Season_yield  \\\n",
       "0      1  groundnut        1        ADILABAD  2016-2017  kharif             0   \n",
       "1      2  groundnut       11   KOMARAM BHEEM  2016-2017  kharif             0   \n",
       "2      4  groundnut       13      MANCHERIAL  2016-2017  kharif          1930   \n",
       "3      5  groundnut       21          NIRMAL  2016-2017  kharif             0   \n",
       "4      6  groundnut       22       NIZAMABAD  2016-2017  kharif          1930   \n",
       "5      7  groundnut        4         JAGTIAL  2016-2017  kharif             0   \n",
       "6      8  groundnut       23      PEDDAPALLI  2016-2017  kharif             0   \n",
       "7      9  groundnut        6     JAYASHANKAR  2016-2017  kharif          3723   \n",
       "8     10  groundnut        2       BHADRADRI  2016-2017  kharif          1930   \n",
       "9     11  groundnut       16     MAHABUBABAD  2016-2017  kharif          3723   \n",
       "10    12  groundnut       31  WARANGAL RURAL  2016-2017  kharif          3723   \n",
       "11    13  groundnut       32  WARANGAL URBAN  2016-2017  kharif          3723   \n",
       "12    14  groundnut        9      KARIMNAGAR  2016-2017  kharif          1930   \n",
       "13    15  groundnut       24         RAJANNA  2016-2017  kharif             0   \n",
       "14    16  groundnut        8       KAMAREDDY  2016-2017  kharif             0   \n",
       "15    17  groundnut       26      SANGAREDDY  2016-2017  kharif          1930   \n",
       "16    18  groundnut       14           MEDAK  2016-2017  kharif          1930   \n",
       "17    19  groundnut       27        SIDDIPET  2016-2017  kharif          1930   \n",
       "18    20  groundnut        5         JANGAON  2016-2017  kharif          3723   \n",
       "19    21  groundnut       33         YADADRI  2016-2017  kharif          1671   \n",
       "\n",
       "    Total  \n",
       "0    2068  \n",
       "1    2068  \n",
       "2    2066  \n",
       "3    2068  \n",
       "4    2044  \n",
       "5    1794  \n",
       "6    2068  \n",
       "7    2151  \n",
       "8    2186  \n",
       "9    1353  \n",
       "10   3265  \n",
       "11   2416  \n",
       "12   2411  \n",
       "13   2068  \n",
       "14   2068  \n",
       "15   2049  \n",
       "16   2062  \n",
       "17   2066  \n",
       "18   1516  \n",
       "19   1736  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S.No            0\n",
       "Crop            0\n",
       "Dist_id         0\n",
       "District        0\n",
       "Year            0\n",
       "Season          0\n",
       "Season_yield    0\n",
       "Total           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of missing data points per column\n",
    "missing_values_count = df.isnull().sum()\n",
    "missing_values_count[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# how many total missing values do we have?\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "percent_missing = (total_missing/total_cells) * 100\n",
    "print(percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S.No            0\n",
       "Crop            0\n",
       "Dist_id         0\n",
       "District        0\n",
       "Year            0\n",
       "Season          0\n",
       "Season_yield    0\n",
       "Total           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the # of missing points in the first ten columns\n",
    "missing_values_count[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module \n",
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This sheet is too large! Your sheet size is: 9299826, 6 Max sheet size is: 1048576, 16384",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0becb9597fe2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                      how = \"left\") \n\u001b[0;32m     11\u001b[0m \u001b[1;31m# creating a new file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mf3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results.xlsx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[0;32m   2254\u001b[0m             \u001b[0mstartcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2255\u001b[0m             \u001b[0mfreeze_panes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2256\u001b[1;33m             \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2257\u001b[0m         )\n\u001b[0;32m   2258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[0;32m    722\u001b[0m                 \u001b[1;34m\"This sheet is too large! Your sheet size is: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m                 \u001b[1;33m+\u001b[0m \u001b[1;34m\"{}, {} \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m                 \u001b[1;33m+\u001b[0m \u001b[1;34m\"Max sheet size is: {}, {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m             )\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This sheet is too large! Your sheet size is: 9299826, 6 Max sheet size is: 1048576, 16384"
     ]
    }
   ],
   "source": [
    "# reading the files \n",
    "f1 = pandas.read_excel(\"1_yield_data.xlsx\") \n",
    "f2 = pandas.read_excel(\"6_weather_data_.xlsx\") \n",
    "# merging the files \n",
    "f3 = f1[[\"Dist_id\",\"Crop\",  \n",
    "         \"Season_yield\"]].merge(f2[[\"Dist_id\",  \n",
    "                                         \"District\", \"crop_season\",  \n",
    "                                         \"Rainfall\"]],  \n",
    "                                     on = \"Dist_id\",  \n",
    "                                     how = \"left\") \n",
    "# creating a new file \n",
    "f3.to_excel(\"Results.xlsx\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names\n",
    "column_names = df.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check if the column is unique\n",
    "for i in column_names:\n",
    "  print('{} is unique: {}'.format(i, df[i].is_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the index values\n",
    "df.index.values\n",
    "# Check if a certain index exists\n",
    "'foo' in df.index.values\n",
    "# If index does not exist\n",
    "#df.set_index('column_name_to_use', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list comprehension of the columns you want to lose\n",
    "columns_to_drop = [column_names[i] for i in [1, 3, 5]]\n",
    "# Drop unwanted columns\n",
    "df.drop(columns_to_drop, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with ' '\n",
    "df['col'] = df['col'].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with 99\n",
    "df['col'] = df['col'].fillna(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with the mean of the column\n",
    "df['col'] = df['col'].fillna(df['col'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'col1':[np.nan, np.nan, 2,3,4, np.nan, np.nan]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='pad', limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading or reading the file\n",
    "# Encoding error\n",
    "# inconsistent rows\n",
    "df=pd.read_excel(r\"E:\\udmey\\Precision Farming to Impove the yield\\1_yield_data.xlsx\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_excel(r\"E:\\udmey\\Precision Farming to Impove the yield\\6_weather_data_.xlsx\")\n",
    "print(df1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.min() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[S.No]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1,thresh=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns=df1.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull.any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Number of Missing NA\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding A Default value or filling the missing data\n",
    "df1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_width_0=df1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A series Object From A Python list\n",
    "ice_cream=['chocolate','vanilla',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
